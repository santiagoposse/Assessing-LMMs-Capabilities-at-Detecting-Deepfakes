{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ollama.Client()\n",
    "llava_7b_model = 'llava'\n",
    "minicpm_8b_model = 'minicpm-v'\n",
    "llava_llama_model = 'llava-llama3'\n",
    "llama3_11b_model = 'llama3.2-vision'\n",
    "gemma3_12b_model = 'gemma3:12b'\n",
    "bakllava_model = 'bakllava'\n",
    "wiki_folder_path = 'wiki'\n",
    "wiki_sample_path = 'wiki_sample'\n",
    "inpainting_folder_path = 'inpainting'\n",
    "inpainting_sample_path = 'inpainting_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava, llava_llama, minicpm, bakllava, llama3, gemma3 = 'llava', 'llava_llama', 'minicpm', 'bakllava', 'llama3', 'gemma3'\n",
    "\n",
    "\n",
    "prompt1 = 'Is this picture a deepfake, answer with only yes or no.'\n",
    "prompt2 = 'Has the person in the picture been altered or augmented in any way, answer with only yes or no.'\n",
    "prompt3 = 'Analyze this image and determine if it is a deepfake. Provide a answer, along with an explanation of your reasoning.'\n",
    "prompt4 = 'Analyze the image of a person for signs of deepfake augmentation or manipulation. Look for specific indicators, including: facial inconsistencies, skin texture anomalies, eye and teeth issues, edge artifacts, lighting mismatches, background distortions. Based on your analysis, do you find evidence of deepfake manipulation? If so, list the specific indicators you detected and explain why they suggest deepfake manipulation. If no evidence is found, state that there are no clear signs of deepfake augmentation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_prompt_run_model(model_name, current_model, current_prompt, prompt_number):\n",
    "    for item in os.listdir(wiki_folder_path):\n",
    "        images = os.path.join(wiki_folder_path, item)\n",
    "\n",
    "        try:    \n",
    "            wiki_model_responses = client.chat(\n",
    "                model=current_model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': current_prompt,\n",
    "                        'images': [images],\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            with open(f'{model_name}_wiki_responses_{prompt_number}.csv', 'a') as f:\n",
    "                f.write(f'{wiki_model_responses.message.content}, {images}\\n')\n",
    "        \n",
    "        except Exception as api_error:\n",
    "            print(f\"API error with {images}: {api_error}\")\n",
    "            continue\n",
    "\n",
    "    for item in os.listdir(test_imgaes):\n",
    "        images = os.path.join(test_imgaes, item)\n",
    "\n",
    "        try:\n",
    "            inpainting_model_responses = client.chat(\n",
    "                model=current_model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': current_prompt,\n",
    "                        'images': [images],\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            with open(f'{model_name}_inpainting_responses_{prompt_number}.csv', 'a') as f:\n",
    "                f.write(f'{inpainting_model_responses.message.content}, {images}\\n')\n",
    "        \n",
    "        except Exception as api_error:\n",
    "            print(f\"API error with {images}: {api_error}\")\n",
    "            continue\n",
    "\n",
    "def explanitory_prompt_run_model(model_name, current_model, current_prompt, prompt_number):\n",
    "    for item in os.listdir(wiki_sample_path):\n",
    "        images = os.path.join(wiki_sample_path, item)\n",
    "\n",
    "        try:    \n",
    "            wiki_model_responses = client.chat(\n",
    "                model=current_model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': current_prompt,\n",
    "                        'images': [images],\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            with open(f'{model_name}_wiki_responses_{prompt_number}.txt', 'a') as f:\n",
    "                f.write(f'{wiki_model_responses.message.content}, {images}\\n')\n",
    "                f.write('---------------------------------------\\n')\n",
    "        \n",
    "        except Exception as api_error:\n",
    "            print(f\"API error with {images}: {api_error}\")\n",
    "            continue\n",
    "\n",
    "    for item in os.listdir(inpainting_sample_path):\n",
    "        images = os.path.join(inpainting_sample_path, item)\n",
    "\n",
    "        try:\n",
    "            inpainting_model_responses = client.chat(\n",
    "                model=current_model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': current_prompt,\n",
    "                        'images': [images],\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            with open(f'{model_name}_inpainting_responses_{prompt_number}.txt', 'a') as f:\n",
    "                f.write(f'{inpainting_model_responses.message.content}, {images}\\n')\n",
    "                f.write('---------------------------------------\\n')\n",
    "        \n",
    "        except Exception as api_error:\n",
    "            print(f\"API error with {images}: {api_error}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prompt_run_model(llava, llava_7b_model, prompt1, 1)\n",
    "binary_prompt_run_model(llava, llava_7b_model, prompt2, 2)\n",
    "explanitory_prompt_run_model(llava, llava_7b_model, prompt3, 3)\n",
    "explanitory_prompt_run_model(llava, llava_7b_model, prompt4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prompt_run_model(llava_llama, llava_llama_model, prompt1, 1)\n",
    "binary_prompt_run_model(llava_llama, llava_llama_model, prompt2, 2)\n",
    "explanitory_prompt_run_model(llava_llama, llava_llama_model, prompt3, 3)\n",
    "explanitory_prompt_run_model(llava_llama, llava_llama_model, prompt4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prompt_run_model(minicpm, minicpm_8b_model, prompt1, 1)\n",
    "binary_prompt_run_model(minicpm, minicpm_8b_model, prompt2, 2)\n",
    "explanitory_prompt_run_model(minicpm, minicpm_8b_model, prompt3, 3)\n",
    "explanitory_prompt_run_model(minicpm, minicpm_8b_model, prompt4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prompt_run_model(bakllava, bakllava_model, prompt1, 1)\n",
    "binary_prompt_run_model(bakllava, bakllava_model, prompt2, 2)\n",
    "explanitory_prompt_run_model(bakllava, bakllava_model, prompt3, 3)\n",
    "explanitory_prompt_run_model(bakllava, bakllava_model, prompt4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prompt_run_model(llama3, llama3_11b_model, prompt1, 1)\n",
    "binary_prompt_run_model(llama3, llama3_11b_model, prompt2, 2)\n",
    "explanitory_prompt_run_model(llama3, llama3_11b_model, prompt3, 3)\n",
    "explanitory_prompt_run_model(llama3, llama3_11b_model, prompt4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prompt_run_model(gemma3, gemma3_12b_model, prompt1, 1)\n",
    "binary_prompt_run_model(gemma3, gemma3_12b_model, prompt2, 2)\n",
    "explanitory_prompt_run_model(gemma3, gemma3_12b_model, prompt3, 3)\n",
    "explanitory_prompt_run_model(gemma3, gemma3_12b_model, prompt4, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap5610",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
